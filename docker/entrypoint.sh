#!/bin/bash
# Lantrn Agent Builder - Docker Entrypoint Script
# Optimized for Mac Ultra (ARM64) + NAS deployment

set -e

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# Display startup banner
echo ""
echo "╔══════════════════════════════════════════════════════════════╗"
echo "║           LANTRN AGENT BUILDER - DOCKER CONTAINER            ║"
echo "║                  On-Prem AI Agent System                     ║"
echo "╚══════════════════════════════════════════════════════════════╝"
echo ""

log_info "Starting Lantrn Agent Builder..."
log_info "Architecture: $(uname -m)"
log_info "Python version: $(python --version)"

# Set workspace directory
WORKSPACE_DIR="${LANTRN_WORKSPACE:-/app/workspace}"
log_info "Workspace: $WORKSPACE_DIR"

# Create necessary directories
log_info "Initializing workspace directories..."
mkdir -p "$WORKSPACE_DIR/.bmad/profiles" \
         "$WORKSPACE_DIR/.bmad/blueprints" \
         "$WORKSPACE_DIR/.bmad/runs" \
         "$WORKSPACE_DIR/agents" \
         "$WORKSPACE_DIR/policies" \
         "$WORKSPACE_DIR/logs" \
         "$WORKSPACE_DIR/data/chromadb" \
         "$WORKSPACE_DIR/config"

# Check for Ollama connectivity
log_info "Checking Ollama connectivity..."
OLLAMA_HOST="${OLLAMA_HOST:-ollama:11434}"
OLLAMA_URL="http://$OLLAMA_HOST"

max_retries=30
retry_count=0
ollama_ready=false

while [ $retry_count -lt $max_retries ]; do
    if curl -s -f "$OLLAMA_URL/api/tags" > /dev/null 2>&1; then
        ollama_ready=true
        break
    fi
    retry_count=$((retry_count + 1))
    log_warning "Waiting for Ollama at $OLLAMA_URL... (attempt $retry_count/$max_retries)"
    sleep 2
done

if [ "$ollama_ready" = true ]; then
    log_success "Ollama is available at $OLLAMA_URL"
    
    # List available models
    log_info "Available Ollama models:"
    curl -s "$OLLAMA_URL/api/tags" | python -c "import sys, json; models = json.load(sys.stdin).get('models', []); [print(f'  - {m[\"name\"]}') for m in models]" 2>/dev/null || log_warning "Could not list models"
else
    log_warning "Ollama is not available at $OLLAMA_URL"
    log_warning "Some features may not work correctly"
fi

# Check for ChromaDB connectivity (if configured)
if [ -n "$CHROMA_SERVER_HOST" ]; then
    log_info "Checking ChromaDB connectivity..."
    CHROMA_URL="http://${CHROMA_SERVER_HOST}:${CHROMA_SERVER_PORT:-8000}"
    
    retry_count=0
    chroma_ready=false
    
    while [ $retry_count -lt $max_retries ]; do
        if curl -s -f "$CHROMA_URL/api/v1/heartbeat" > /dev/null 2>&1; then
            chroma_ready=true
            break
        fi
        retry_count=$((retry_count + 1))
        log_warning "Waiting for ChromaDB at $CHROMA_URL... (attempt $retry_count/$max_retries)"
        sleep 2
    done
    
    if [ "$chroma_ready" = true ]; then
        log_success "ChromaDB is available at $CHROMA_URL"
    else
        log_warning "ChromaDB is not available, using local storage"
    fi
fi

# Verify Playwright browsers
log_info "Verifying Playwright browsers..."
if [ -d "/ms-playwright/chromium" ]; then
    log_success "Playwright Chromium browser is installed"
else
    log_warning "Playwright browsers not found, installing..."
    playwright install chromium --with-deps 2>/dev/null || log_error "Failed to install Playwright browsers"
fi

# Initialize default configuration if not exists
CONFIG_FILE="$WORKSPACE_DIR/config/settings.yaml"
if [ ! -f "$CONFIG_FILE" ]; then
    log_info "Creating default configuration..."
    cat > "$CONFIG_FILE" << 'YAML'
# Lantrn Agent Builder - Default Configuration
# Generated by Docker entrypoint

model_profiles:
  fast:
    provider: ollama
    model: llama3.2:3b
    ctx_length: 128000
    temperature: 0.7
  hq:
    provider: ollama
    model: llama3.1:70b
    ctx_length: 128000
    temperature: 0.5

default_profile: fast

logging:
  level: INFO
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"

workspace:
  data_dir: /app/workspace/data
  logs_dir: /app/workspace/logs
YAML
    log_success "Default configuration created"
fi

# Display environment info
log_info "Environment: ${LANTRN_ENV:-production}"
log_info "Log level: ${LANTRN_LOG_LEVEL:-INFO}"
log_info "Default model: ${DEFAULT_MODEL:-llama3.2:3b}"

# Start the application
log_success "Starting Lantrn Agent Builder API server..."
echo ""

# Execute the command
exec "$@"
